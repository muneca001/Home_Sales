# Home Sales SparkSQL Project

## Overview
This SparkSQL project involves analyzing a home sales dataset to derive key metrics. The tasks include creating temporary views, partitioning data, caching tables, and running SparkSQL queries to obtain insights. The project showcases proficiency in SparkSQL, data manipulation, and optimization techniques.

## Project Tasks
- Create a Spark DataFrame from the home sales dataset.
- Build a temporary table for further analysis.
- Perform queries to find average prices for specific home attributes and view ratings.
- Cache and validate temporary tables for optimized performance.
- Analyze runtime differences between cached and uncached queries.
- Utilize partitioning and parquet data for more efficient storage.
- Run queries on partitioned parquet data and compare run times.
- Ensure proper uncaching of temporary tables.

## Conclusion
This project demonstrates the effective use of SparkSQL for real-world data analysis tasks, showcasing the ability to optimize performance through caching and partitioning strategies.
